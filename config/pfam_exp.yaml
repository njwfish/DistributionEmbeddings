# @package _global_

# Set default configurations
defaults:
  - dataset: pfam
  - encoder: esm
  - model: bert_gpt2_mlp # Placeholder, not actually used
  - generator: progen2
  - optimizer: adam
  - scheduler: cosine
  - training: fast
  - wandb: default
  - mixer: none
  - override hydra/launcher: slurm
  - _self_

experiment:
  latent_dim: 128
  hidden_dim: 256
  batch_size: 1
  lr: 2e-5
  
training:
  eval_interval: 1  # Evaluate every 500 steps
  save_interval: 1  # Save checkpoint every 1000 steps
  
# General settings
seed: 42
device: cuda
experiment_name: pfam_exp

# Hydra-related settings
hydra:
  run:
    dir: outputs/${experiment_name}/${now:%Y-%m-%d_%H-%M-%S}
  sweep:
    dir: multirun/${experiment_name}/${now:%Y-%m-%d_%H-%M-%S}
    subdir: ${hydra.job.num}
  job:
    config:
      override_dirname:
        exclude_keys:
          - seed
          - device
          - hydra
          - experiment_name 